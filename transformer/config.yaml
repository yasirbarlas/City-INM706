model:
  hidden_size: 512
  max_seq_length: 50
  num_layers: 6
  expansion_factor: 4
  n_heads: 8
train:
  epochs: 50
  batch_size: 64
  optimizer: "adam" # "adamW", "radam", "adam"
  loss_function: "cross-entropy" # "cross-entropy", "negative-log"
  learning_rate: 0.001
  betas: (0.9, 0.98)
  eps: 1e-9
